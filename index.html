<!DOCTYPE html><html><head><meta charset="UTF-8"></head><script src="https://unpkg.com/react@16/umd/react.development.js" crossorigin></script><script src="https://unpkg.com/react-dom@16/umd/react-dom.development.js" crossorigin></script><!-- Load our React component. --><script src="like_button.js"></script>      <script>
        document.addEventListener('DOMContentLoaded', function(){
          function clock() {
            function shuffle(a) {
              for (let i = a.length - 1; i > 0; i--) {
                  const j = Math.floor(Math.random() * (i + 1));
                  [a[i], a[j]] = [a[j], a[i]];
              }
              return a;
            }

            var cvs = document.getElementById('myCanvas')
            var farts = document.getElementById('farts')
            cvs.height = window.innerHeight
            cvs.width = window.innerWidth - farts.offsetWidth
            var ctx = cvs.getContext('2d');
            ctx.scale(0.3, 0.3);

            // if you remove this it makes the lines get all pixelated lol wonder why
            ctx.beginPath();

            var move1 = shuffle([10, 50, 100, 250])
            ctx.moveTo(move1,50);

            var curve_values = [10, 100, 1000, 20, 200, 2000, 30, 300, 3000, 40, 400, 4000, 50, 500, 5000, 60, 600, 6000, 70, 700, 7000, 80, 800, 8000, 90, 900, 9000]
            var to_sample = shuffle(curve_values)
            var a = to_sample[0]
            var b = to_sample[1]
            var c = to_sample[2]
            var d = to_sample[3]
            var e = to_sample[4]
            var f = to_sample[5]
            ctx.bezierCurveTo(a,b,c,d,e,f);

            ctx.stroke();

            setTimeout(() => {
              window.requestAnimationFrame(clock);
            }, 150)
          }
          window.requestAnimationFrame(clock);
        });
      </script>
<button onclick='var elem = document.getElementById("myCanvas");elem.parentElement.removeChild(elem)'>No Mas Bezier</button>
<div style='display: flex'><span id='farts'><button onclick="document.body.background = ''">Sandwich Off</button>
<button onclick="document.body.background = 'sandwich.jpg'">Sandwich On</button>
<h2><span style='color: orange'>I</span>
<span style='color: red'>'</span>
<span style='color: orange'>m</br></span>
</h2><h2><span style='color: red'>B</span>
<span style='color: orange'>o</span>
<span style='color: light blue'>b</span>
<span style='color: orange'>b</span>
<span style='color: red'>y</span>
<span style='color: red'>.</br></span>
</h2><h2><span style='color: red'>I</span>
<span style='color: orange'>'</span>
<span style='color: orange'>m</br></span>
</h2><h2><span style='color: orange'>a</br></span>
</h2><h2><span style='color: red'>p</span>
<span style='color: light blue'>r</span>
<span style='color: orange'>o</span>
<span style='color: light blue'>g</span>
<span style='color: light blue'>r</span>
<span style='color: light blue'>a</span>
<span style='color: orange'>m</span>
<span style='color: red'>m</span>
<span style='color: red'>e</span>
<span style='color: orange'>r</br></span>
</h2><h2><span style='color: red'>i</span>
<span style='color: light blue'>n</br></span>
</h2><h2><span style='color: light blue'>N</span>
<span style='color: orange'>e</span>
<span style='color: red'>w</br></span>
</h2><h2><span style='color: red'>Y</span>
<span style='color: red'>o</span>
<span style='color: orange'>r</span>
<span style='color: orange'>k</span>
<span style='color: red'>.</br></span>
</h2><h2><span style='color: light blue'>M</span>
<span style='color: red'>y</br></span>
</h2><h2><span style='color: light blue'>g</span>
<span style='color: red'>i</span>
<span style='color: orange'>t</span>
<span style='color: orange'>h</span>
<span style='color: red'>u</span>
<span style='color: light blue'>b</span>
<span style='color: light blue'>'</span>
<span style='color: red'>s</br></span>
</h2><h2><span style='color: orange'>@</span>
<span style='color: orange'>n</span>
<span style='color: light blue'>o</span>
<span style='color: orange'>t</span>
<span style='color: red'>a</span>
<span style='color: red'>c</span>
<span style='color: red'>t</span>
<span style='color: light blue'>u</span>
<span style='color: orange'>a</span>
<span style='color: red'>l</span>
<span style='color: red'>l</span>
<span style='color: red'>y</span>
<span style='color: red'>p</span>
<span style='color: red'>a</span>
<span style='color: light blue'>g</span>
<span style='color: red'>e</span>
<span style='color: red'>m</span>
<span style='color: light blue'>c</span>
<span style='color: red'>c</span>
<span style='color: orange'>o</span>
<span style='color: red'>n</span>
<span style='color: red'>n</span>
<span style='color: light blue'>e</span>
<span style='color: light blue'>l</span>
<span style='color: orange'>l</span>
<span style='color: orange'>.</br></span>
</h2><h2><span style='color: red'>I</br></span>
</h2><h2><span style='color: orange'>l</span>
<span style='color: orange'>i</span>
<span style='color: red'>k</span>
<span style='color: red'>e</br></span>
</h2><h2><span style='color: red'>i</span>
<span style='color: orange'>m</span>
<span style='color: red'>p</span>
<span style='color: orange'>r</span>
<span style='color: red'>o</span>
<span style='color: orange'>v</span>
<span style='color: red'>v</span>
<span style='color: orange'>y</br></span>
</h2><h2><span style='color: red'>m</span>
<span style='color: light blue'>u</span>
<span style='color: red'>s</span>
<span style='color: red'>i</span>
<span style='color: red'>c</span>
<span style='color: red'>,</br></span>
</h2><h2><span style='color: light blue'>e</span>
<span style='color: red'>s</span>
<span style='color: light blue'>p</span>
<span style='color: orange'>e</span>
<span style='color: orange'>c</span>
<span style='color: orange'>i</span>
<span style='color: light blue'>a</span>
<span style='color: orange'>l</span>
<span style='color: red'>l</span>
<span style='color: red'>y</br></span>
</h2><h2><span style='color: red'>P</span>
<span style='color: orange'>h</span>
<span style='color: light blue'>i</span>
<span style='color: light blue'>s</span>
<span style='color: red'>h</span>
<span style='color: light blue'>.</br></span>
</h2></span><canvas id='myCanvas'></canvas></div></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br><h1>Supervisory Strategies in Elixir</h1>

<p>One of the things that makes OTP and Elixir unique is the model of supervisor behaviour that applications can take with different processes they start.
In this post we will examine each of the three available in Elixir by making a supervised app.</p>

<p>To start, we make a supervised application:</p>

<pre><code>mix new counter --sup
cd counter
</code></pre>

<p>Now that we have an app, we are going to create 3 modules.
They will all be GenServers that are started with the application who send themselves a message every second to increment their state by one.
One will always work, one will fail every 6 messages, and one will fail every 20 messages.
To start, it will have the default supervisory strategy of <code>one_for_one</code> in <code>application.ex</code>.
This strategy says that if one process dies, its siblings should stay working unaffected.</p>

<p><strong>Note: No matter your supervisory strategy, if the children in your app do not succeed on <code>start_link</code> and return an <code>{:ok, pid}</code> tuple, the application as a whole will not start and your supervisory strategy does not matter at all.</strong></p>

<p>We will stick with that in the beginning.</p>

<p>Let's start with the first module in <code>lib/counter/one.ex</code>.
It will fail if its state is 22.</p>

<pre><code class="elixir">defmodule Counter.One do
  use GenServer

  def start_link(_state \\ 0) do
    IO.inspect("starting", label: "Counter.One")
    success = GenServer.start_link(__MODULE__, 0)
    IO.inspect("started", label: "Counter.One")
    success 
  end

  @impl true
  def init(state) do
    work(state)
    # Schedule work to be performed on start
    schedule_work()
    {:ok, state}
  end

  @impl true
  def handle_info(:work, state) do
    work(state)
    # Reschedule once more
    schedule_work()
    {:noreply, state + 1}
  end

  defp schedule_work() do
    Process.send_after(self(), :work, 1000)
  end

  def work(state) do
    case state do
      22 -&gt; raise "I'm Counter.One and I'm gonna error now"
      _ -&gt; IO.inspect("working and my state is #{state}", label: "Counter.One")
    end
  end
end
</code></pre>

<p>Note:
This is slight modification of a <a href="https://hexdocs.pm/elixir/GenServer.html#module-receiving-regular-messages">great example from the GenServer docs</a>.
Also see <a href="http://elixirschool.com/blog/til-send-after/">this past Elixir School blog post</a> for more on <code>Process.send_after/3</code>.</p>

<p>Now, if we open <code>lib/counter/application.ex</code> and add it to children, we can get it to start with our app:</p>

<pre><code class="elixir">defmodule Counter.Application do
  # See https://hexdocs.pm/elixir/Application.html
  # for more information on OTP Applications
  @moduledoc false

  use Application

  def start(_type, _args) do
    # List all child processes to be supervised
    children = [
      Counter.One
    ]

    # See https://hexdocs.pm/elixir/Supervisor.html
    # for other strategies and supported options
    opts = [strategy: :one_for_one, name: Counter.Supervisor]
    Supervisor.start_link(children, opts)
  end
end
</code></pre>

<p>Now if we start the app, we will see it begin to work and fail at 22:</p>

<pre><code>Counter.One: "working and my state is 18"
Counter.One: "working and my state is 19"
Counter.One: "working and my state is 20"
Counter.One: "working and my state is 21"
Counter.One: "starting"
Counter.One: "working and my state is 0"
Counter.One: "started"

18:27:42.566 [error] GenServer #PID&lt;0.119.0&gt; terminating
** (RuntimeError) I'm Counter.One and I'm gonna error now
    (one) lib/counter/one.ex:33: Counter.One.work/1
    (one) lib/counter/one.ex:21: Counter.One.handle_info/2
    (stdlib) gen_server.erl:616: :gen_server.try_dispatch/4
    (stdlib) gen_server.erl:686: :gen_server.handle_msg/6
    (stdlib) proc_lib.erl:247: :proc_lib.init_p_do_apply/3
Last message: :work
State: 22
Counter.One: "working and my state is 0"
Counter.One: "working and my state is 1"
</code></pre>

<p>This fails because we made a specific clause to coerce failure by raising an error when the state reached <code>22</code> in our counter.
It is restarted with a state 0 (the default) after this failure.</p>

<p>Now lets make another module that will never fail:
```elixir
defmodule Counter.Two do
  use GenServer</p>

<p>  def start_link(_state \ 0) do
    IO.inspect("starting", label: "Counter.Two")
    success = GenServer.start_link(<strong>MODULE</strong>, 0)
    IO.inspect("started", label: "Counter.Two")
    success
  end</p>

<p>  @impl true
  def init(state) do
    work(state)
    # Schedule work to be performed on start
    schedule_work()
    {:ok, state}
  end</p>

<p>  @impl true
  def handle_info(:work, state) do
    work(state)
    # Reschedule once more
    schedule_work()
    {:noreply, state + 1}
  end</p>

<p>  defp schedule_work() do
    Process.send_after(self(), :work, 1000)
  end</p>

<p>  def work(state) do
    IO.inspect("working and my state is #{state}", label: "Counter.Two")
  end
end
```</p>

<p>We can add it to <code>lib/counter/application.ex</code> as well.</p>

<pre><code class="elixir">  # ...
  def start(_type, _args) do
    # List all child processes to be supervised
    children = [
      Counter.One,
      Counter.Two
    ]
  end
  # ...
</code></pre>

<p>Now, for our third and final module that will fail if state is <code>5</code>.</p>

<pre><code class="elixir">defmodule Counter.Three do
  use GenServer

  def start_link(_state \\ 0) do
    IO.inspect("starting", label: "Counter.Three")
    success = GenServer.start_link(__MODULE__, 0)
    IO.inspect("started", label: "Counter.Three")
    success 
  end

  @impl true
  def init(state) do
    work(state)
    # Schedule work to be performed on start
    schedule_work()
    {:ok, state}
  end

  @impl true
  def handle_info(:work, state) do
    work(state)
    # Reschedule once more
    schedule_work()
    {:noreply, state + 1}
  end

  defp schedule_work() do
    Process.send_after(self(), :work, 1000)
  end

  def work(state) do
    case state do
      5 -&gt; raise "I'm Counter.Three and I'm gonna error now"
      _ -&gt; IO.inspect("working and my state is #{state}", label: "Counter.Three")
    end
  end
end
</code></pre>

<p>We can add it to <code>lib/counter/application.ex</code> in the list of children, last after the other two:</p>

<pre><code class="elixir">  # ...
  def start(_type, _args) do
    # List all child processes to be supervised
    children = [
      Counter.One,
      Counter.Two,
      Counter.Three
    ]
  end
  # ...
</code></pre>

<h2>One For One</h2>

<p>Now, let's start our application and see the failure behaviour and state for each GenServer.
These logs are truncated to just the interesting parts.</p>

<pre><code>Counter.One: "working and my state is 4"
Counter.Two: "working and my state is 4"
Counter.Three: "working and my state is 4"
Counter.Two: "working and my state is 5"
Counter.Three: "working and my state is 5"
Counter.One: "starting"
Counter.One: "working and my state is 0"
Counter.One: "started"

18:11:37.495 [error] GenServer #PID&lt;0.130.0&gt; terminating
** (RuntimeError) I'm Counter.One and I'm gonna error now
    (counter) lib/counter/one.ex:33: Counter.One.work/1
    (counter) lib/counter/one.ex:21: Counter.One.handle_info/2
    (stdlib) gen_server.erl:616: :gen_server.try_dispatch/4
    (stdlib) gen_server.erl:686: :gen_server.handle_msg/6
    (stdlib) proc_lib.erl:247: :proc_lib.init_p_do_apply/3
Last message: :work
State: 5
Counter.Three: "working and my state is 6"
Counter.Two: "working and my state is 6"
Counter.One: "working and my state is 0"
Counter.Three: "working and my state is 7"
Counter.Two: "working and my state is 7"
Counter.One: "working and my state is 1"
</code></pre>

<p>So, we can see our first crash.
The process for <code>Counter.One</code> failed with our raised error, and was restarted.
Because our default strategy in Elixir is <code>one_for_one</code>, this is expected.
In the default configuration, we dont want one child processes failure to effect any others.</p>

<p>If we let it continue to 22 with <code>Counter.One</code>, we would see the same behaviour (allow a crash without impacting any siblings, as its one for one).</p>

<h2>Rest For One</h2>

<p>Now let's try it with <code>rest_for_one</code>.
Rest for one as a strategy starts the children in sequence, and if a later child fails the ones before it do too.
We want to change our line assigning <code>opts</code> in <code>lib/counter/application.ex</code> to state that.</p>

<pre><code class="elixir"># ...
    children = [
      Counter.One,
      Counter.Two,
      Counter.Three
    ]

    opts = [strategy: :rest_for_one, name: Counter.Supervisor]
# ...
</code></pre>

<p>Now, let's start up again.
These logs are also truncated to the interesting part</p>

<pre><code>Counter.One: "working and my state is 3"
Counter.Two: "working and my state is 3"
Counter.Three: "working and my state is 3"
Counter.One: "working and my state is 4"
Counter.Two: "working and my state is 4"
Counter.Three: "working and my state is 4"
Counter.One: "working and my state is 5"
Counter.Two: "working and my state is 5"
Counter.Three: "starting"

18:30:56.925 [error] GenServer #PID&lt;0.134.0&gt; terminating
** (RuntimeError) I'm Counter.Three and I'm gonna error now
    (counter) lib/counter/three.ex:33: Counter.Three.work/1
    (counter) lib/counter/three.ex:21: Counter.Three.handle_info/2
    (stdlib) gen_server.erl:616: :gen_server.try_dispatch/4
    (stdlib) gen_server.erl:686: :gen_server.handle_msg/6
    (stdlib) proc_lib.erl:247: :proc_lib.init_p_do_apply/3
Last message: :work
State: 5
Counter.Three: "working and my state is 0"
Counter.Three: "started"
Counter.One: "working and my state is 6"
Counter.Two: "working and my state is 6"
Counter.Three: "working and my state is 0"
Counter.One: "working and my state is 7"
Counter.Two: "working and my state is 7"
</code></pre>

<p>The key takeaway here is <em>order matters</em>.
Because <code>Counter.Three</code> doesn't fail until <code>22</code> is its state, and <code>Counter.One</code> fails with a state of <code>5</code>, <code>Counter.Three</code> will force a restart of all 3 children since its last, but <code>Counter.One</code>'s failures have no effect on its siblings.</p>

<h2>One For All</h2>

<p>Now let's enable it with <code>one_for_all</code>.
In this supervisory model if one child fails, all must be restarted.
To do this lets change <code>lib/counter/application.ex</code> again.</p>

<pre><code class="elixir">    opts = [strategy: :one_for_all, name: Counter.Supervisor]
</code></pre>

<p>If we start our app again with <code>iex -S mix</code> we can see the behaviour as soon as <code>Counter.Three</code> reaches a state of 5, but it again will confirm that it works the same again when we reach 22.</p>

<pre><code>Counter.Two: "working and my state is 4"
Counter.One: "working and my state is 5"
Counter.Two: "working and my state is 5"
Counter.One: "starting"
Counter.One: "working and my state is 0"
Counter.One: "started"
Counter.Two: "starting"
Counter.Two: "working and my state is 0"
Counter.Two: "started"
Counter.Three: "starting"
Counter.Three: "working and my state is 0"
Counter.Three: "started"

18:34:56.122 [error] GenServer #PID&lt;0.121.0&gt; terminating
** (RuntimeError) I'm Counter.Three and I'm gonna error now
    (counter) lib/counter/three.ex:33: Counter.Three.work/1
    (counter) lib/counter/three.ex:21: Counter.Three.handle_info/2
    (stdlib) gen_server.erl:616: :gen_server.try_dispatch/4
    (stdlib) gen_server.erl:686: :gen_server.handle_msg/6
    (stdlib) proc_lib.erl:247: :proc_lib.init_p_do_apply/3
Last message: :work
State: 5
Counter.One: "working and my state is 0"
Counter.Two: "working and my state is 0"
Counter.Three: "working and my state is 0"
</code></pre>

<p>We could also change the order in the <code>children</code> variable match, and the same thing would happen.</p>

<p>That was a lot to take in, but hopefully the supervisory strategies of Elixir applications are a bit clearer now!</p>
</br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br><h1>Agnostic Elixir/Erlang/OTP Version Management Using <code>asdf</code></h1>

<h2>What is it?</h2>

<p>Oftentimes we need to use multiple versions of our tools.
Many communities have their own things to do this.
In Ruby we have <code>chruby</code>, <code>rbenv</code>, <code>rvm</code> and more, NodeJS has <code>nvm</code>.
These tools allow us to easily and quickly switch what we are using for a given project or environment.</p>

<p>Today were going to talk about my favorite version manager of choice, <code>asdf</code>, because it lets you manage multiple languages with just one tool because it is agnostic as to what you manage the version of with it.
There is one big win that I see with <code>asdf</code> that no other tool has allowed me to do as easily: control which version of OTP my Elixir was compiled with, and manage that and several versions of Elixir + OTP together.
Let's check it out!</p>

<h2>Setup</h2>

<p>Installing <code>asdf</code> is a breeze.</p>

<p>First, clone it down:</p>

<pre><code class="shell">git clone https://github.com/asdf-vm/asdf.git ~/.asdf --branch v0.5.1
</code></pre>

<p>Now its time for setup.</p>

<p>On macOS:</p>

<pre><code class="shell">echo -e '\n. $HOME/.asdf/asdf.sh' &gt;&gt; ~/.bash_profile
echo -e '\n. $HOME/.asdf/completions/asdf.bash' &gt;&gt; ~/.bash_profile
</code></pre>

<p>On linux (with a standard bash shell):</p>

<pre><code class="shell">echo -e '\n. $HOME/.asdf/asdf.sh' &gt;&gt; ~/.bashrc
echo -e '\n. $HOME/.asdf/completions/asdf.bash' &gt;&gt; ~/.bashrc
</code></pre>

<p>With ZSH:</p>

<pre><code class="shell">echo -e '\n. $HOME/.asdf/asdf.sh' &gt;&gt; ~/.zshrc
echo -e '\n. $HOME/.asdf/completions/asdf.bash' &gt;&gt; ~/.zshrc
</code></pre>

<p>With Fish:</p>

<pre><code class="shell">echo 'source ~/.asdf/asdf.fish' &gt;&gt; ~/.config/fish/config.fish
mkdir -p ~/.config/fish/completions; and cp ~/.asdf/completions/asdf.fish ~/.config/fish/completions
</code></pre>

<p>Now restart your shell, and type <code>asdf</code> and we get our first introduction to the tool.</p>

<pre><code class="shell">asdf

MANAGE PLUGINS
  asdf plugin-add &lt;name&gt; [&lt;git-url&gt;]   Add a plugin from the plugin repo OR, add a Git repo
                                       as a plugin by specifying the name and repo url
  asdf plugin-list                     List installed plugins
  [...]

MANAGE PACKAGES
  asdf install &lt;name&gt; &lt;version&gt;        Install a specific version of a package or,
                                       with no arguments, install all the package
                                       versions listed in the .tool-versions file
  asdf uninstall &lt;name&gt; &lt;version&gt;      Remove a specific version of a package
  asdf current                         Display current version set or being used for all packages
  asdf current &lt;name&gt;                  Display current version set or being used for package
  [...]

UTILS
  asdf reshim &lt;name&gt; &lt;version&gt;         Recreate shims for version of a package
  asdf update                          Update asdf to the latest stable release
  asdf update --head                   Update asdf to the latest on the master branch
</code></pre>

<h2>Using it with Elixir</h2>

<p>To get <code>asdf</code> working with Elixir, we first will need Erlang.
Depending on our system, there are some simple steps:</p>

<p>On OSX:</p>

<pre><code class="shell">brew install autoconf wxmac
asdf plugin-add erlang https://github.com/asdf-vm/asdf-erlang.git
asdf install erlang 21.1
</code></pre>

<p>On Ubuntu</p>

<pre><code class="shell">apt-get -y install build-essential autoconf m4 libncurses5-dev libwxgtk3.0-dev libgl1-mesa-dev libglu1-mesa-dev libpng3 libssh-dev
asdf plugin-add erlang https://github.com/asdf-vm/asdf-erlang.git
asdf install erlang 21.1
</code></pre>

<p>For the Erlang bits, we can use any ref from git or also pass a major OTP version.
<code>asdf install erlang ref:master</code> would get us the latest master version from git.
Since we can do this with Elixir, too, you can imagine how easy it makes building from a specific branch or version for debugging contributions to Elixir itself that may involve multiple versions!</p>

<p>Now, let’s get Elixir set up.
It will be the same on all systems since we got our plumbing done with Erlang.</p>

<pre><code class="shell">asdf plugin-add elixir https://github.com/asdf-vm/asdf-elixir.git
asdf install elixir 1.7
</code></pre>

<p>Now, what if we happened to know we needed it compiled on OTP 20 and not OTP 21, and to run in that environment?</p>

<pre><code class="shell">asdf install erlang 20.3
asdf install elixir 1.7-otp-20
</code></pre>

<p>Now, we can set up what version we want to use in a given project (local environment, per directory) like so:</p>

<pre><code class="shell">asdf local erlang 20.3
asdf local elixir 1.7.0-otp-20
</code></pre>

<p>Or alternatively, we can set global configs (our entire system), too:</p>

<pre><code class="shell">asdf global erlang 20.3
asdf global elixir 1.7.0-otp-20
</code></pre>

<p>To learn more about how asdf manages these things under the hood and further customize, check out <a href="https://github.com/asdf-vm/asdf#the-tool-versions-file">their docs</a>.</p>

<p>As you can see, this makes it quite seamless to be able to switch around a toolset that is somewhat complicated underneath the service.
I find <code>asdf</code> to be a great tool for managing this piece of my complexity in my day to day life.
Happy hacking!</p>
</br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br><h1>GenStage Tutorial</h1>

<h2>Introduction</h2>

<p>So what is GenStage?  From the official documentation, it is a "specification and computational flow for Elixir", but what does that mean to us?<br/>
There is a lot to something that can be described as that vague, and here we'll take a dive in and build something on top of it to understand its goals.
We could go into the technical and theoretical implications of this, but instead lets try a pragmatic approach to really just get it to work.</p>

<p>First, Let's imagine we have a server that constantly emits numbers.
It starts at the state of the number we give it, then counts up in one from there onward.
This is what we would call our producer.
Each time it emits a number, this is an event, and we want to handle it with a consumer.
A consumer simply takes what a producer emits and does something to it.
In our case, we will display the count.
There is a lot more to GenStage at a technical and applied level, but we will build up on the specifics and definitions further in later lessons, for now we just want a running example we can build up on.</p>

<h2>Getting Started: A Sample GenStage Project</h2>

<p>We'll begin by generating a simple project that has a supervision tree:</p>

<pre><code class="shell">$ mix new genstage_example --sup
$ cd genstage_example
</code></pre>

<p>Let's set up some basic things for the future of our application.
Since GenStage is generally used as a transformation pipeline, lets imagine we have a background worker of some sort.
This worker will need to persist whatever it changes, so we should get a database set up, but we can worry about that in a later lesson.
To start, all we need to do is add <code>gen_stage</code> to our deps in <code>mix.deps</code>.</p>

<pre><code class="elixir">. . .
  defp deps do
    [
      {:gen_stage, "~&gt; 0.7"},
    ]
  end
. . .
</code></pre>

<p>Now, we should fetch our dependencies and compile before we start setup:</p>

<pre><code class="shell">$ mix do deps.get, compile
</code></pre>

<p>Lets build a producer, our simple beginning building block to help us utilize this new tool!</p>

<h2>Building A Producer</h2>

<p>To get started what we want to do is create a producer that emits a constant stream of events for our consumer to handle.
This is quite simple with the rudimentary example of a counter.
Let's create a namespaced directory under <code>lib</code> and then go from there, this way our module naming matches our names of the modules themselves:</p>

<pre><code class="shell">$ mkdir lib/genstage_example
$ touch lib/genstage_example/producer.ex
</code></pre>

<p>Now we can add the code:</p>

<pre><code class="elixir">defmodule GenstageExample.Producer do
  alias Experimental.GenStage
  use GenStage

  def start_link do
    GenStage.start_link(__MODULE__, 0, name: __MODULE__)
                                       # naming allows us to handle failure
  end

  def init(counter) do
    {:producer, counter}
  end

  def handle_demand(demand, state) do
                    # the default demand is 1000
    events = Enum.to_list(state..state + demand - 1)
             # [0 .. 999]
             # is a filled list, so its going to be considered emitting true events immediately
    {:noreply, events, (state + demand)}
  end
end
</code></pre>

<p>Let's break this down line by line.
To begin with, we have our initial declarations:</p>

<pre><code class="elixir">. . .
defmodule GenstageExample.Producer do
  alias Experimental.GenStage
  use GenStage
. . .
</code></pre>

<p>What this does is a couple simple things.
First, we declare our module, and soon after we alias <code>Experimental.GenStage</code>.
This is simply because we will be calling it more than once and makes it more convenient.
The <code>use GenStage</code> line is much akin to <code>use GenServer</code>.
This line allows us to import the default behaviour and functions to save us from a large amount of boilerplate.</p>

<p>If we go further, we see the first two primary functions for startup:</p>

<pre><code class="elixir">. . .
  def start_link do
    GenStage.start_link(__MODULE__, :the_state_doesnt_matter)
  end

  def init(counter) do
    {:producer, counter}
  end
. . .
</code></pre>

<p>These two functions offer a very simple start.
First, we have our standard <code>start_link/0</code> function.
Inside here, we use<code>GenStage.start_link/</code> beginning with our argument <code>__MODULE__</code>, which will give it the name of our current module.
Next, we set a state, which is arbitrary in this case, and can be any value.
The <code>__MODULE__</code> argument is used for name registration like any other module.
The second argument is the arguments, which in this case are meaningless as we do not care about it.
In <code>init/1</code> we simply set the counter as our state, and label ourselves as a producer.</p>

<p>Finally, we have where the real meat of our code's functionality is:</p>

<pre><code class="elixir">. . .
  def handle_demand(demand, state) do
    events = Enum.to_list(state..state + demand - 1)
    {:noreply, events, (state + demand)}
  end
. . .
</code></pre>

<p><code>handle_demand/2</code> must be implemented by all producer type modules that utilize GenStage.
In this case, we are simply sending out an incrementing counter.
This might not make a ton of sense until we build our consumer, so lets move on to that now.</p>

<h2>Building A Consumer</h2>

<p>The consumer will handle the events that are broadcasted out by our producer.
For now, we wont worry about things like broadcast strategies, or what the internals are truly doing.
We'll start by showing all the code and then break it down.</p>

<pre><code class="elixir">defmodule GenstageExample.Consumer do
  alias Experimental.GenStage
  use GenStage

  def start_link do
    GenStage.start_link(__MODULE__, :state_doesnt_matter)
  end

  def init(state) do
    {:consumer, state, subscribe_to: [GenstageExample.Producer]}
  end

  def handle_events(events, _from, state) do
    for event &lt;- events do
      IO.inspect {self(), event, state}
    end
    {:noreply, [], state}
  end
end
</code></pre>

<p>To start, let's look at the beginning functions just like last time:</p>

<pre><code class="elixir">defmodule GenstageExample.Consumer do
  alias Experimental.GenStage
  use GenStage

  def start_link do
    GenStage.start_link(__MODULE__, :state_doesnt_matter)
  end

  def init(state) do
    {:consumer, state, subscribe_to: [GenstageExample.Producer]}
  end
. . .
</code></pre>

<p>To begin, much like in our producer, we set up our <code>start_link/0</code> and <code>init/1</code> functions.
In <code>start_link</code> we simple register the module name like last time, and set a state.
The state is arbitrary for the consumer, and can be literally whatever we please, in this case <code>:state_doesnt_matter</code>.</p>

<p>In <code>init/1</code> we simply take the state and set up our expected tuple.
It expected use to register our <code>:consumer</code> atom first, then the state given.
Our <code>subscribe_to</code> clause is optional.
What this does is subscribe us to our producer module.
The reason for this is if something crashes, it will simply attempt to re-subscribe and then resume receiving emitted events.</p>

<pre><code class="elixir">. . .
  def handle_events(events, _from, state) do
    for event &lt;- events do
      IO.inspect {self(), event, state}
    end
    {:noreply, [], state}
  end
. . .
</code></pre>

<p>This is the meat of our consumer, <code>handle_events/3</code>.
<code>handle_events/3</code> must be implemented by any <code>consumer</code> or <code>producer_consumer</code> type of GenStage module.
What this does for us is quite simple.
We take a list of events, and iterate through these.
From there, we inspect the <code>pid</code> of our consumer, the event (in this case the current count), and the state.
After that, we don't reply because we are a consumer and do not handle anything, and we don't emit events to the second argument is empty, then we simply pass on the state.</p>

<h2>Wiring It Together</h2>

<p>To get all of this to work we only have to make one simple change.
Open up <code>lib/genstage_example.ex</code> and we can add them as workers and they will automatically start with our application:</p>

<pre><code class="elixir">. . .
    children = [
      worker(GenstageExample.Producer, []),
      worker(GenstageExample.Consumer, []),
    ]
. . .
</code></pre>

<p>With this, if things are all correct, we can run IEx and we should see everything working:</p>

<pre><code class="elixir">iex(1)&gt; {#PID&lt;0.205.0&gt;, 0, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 1, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 2, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 3, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 4, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 5, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 6, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 7, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 8, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 9, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 10, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 11, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 12, :state_doesnt_matter}
. . .
</code></pre>

<h2>Tinkering: For Science and Understanding</h2>

<p>From here, we have a working flow.
There is a producer emitting our counter, and our consumber is displaying all of this and continuing the flow.
Now, what if we wanted multiple consumers?
Right now, if we examine the <code>IO.inspect/1</code> output, we see that every single event is handled by a single PID.
This isn't very Elixir-y.
We have massive concurrency built-in, we should probably leverage that as much as possible.
Let's make some adjustments so that we can have multiple workers by modifying <code>lib/genstage_example.ex</code></p>

<pre><code class="elixir">. . .
    children = [
      worker(GenstageExample.Producer, []),
      worker(GenstageExample.Consumer, [], id: 1),
      worker(GenstageExample.Consumer, [], id: 2),
    ]
. . .
</code></pre>

<p>Now, let's fire up IEx again:</p>

<pre><code class="elixir">$ iex -S mix
iex(1)&gt; {#PID&lt;0.205.0&gt;, 0, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 1, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 2, :state_doesnt_matter}
{#PID&lt;0.207.0&gt;, 3, :state_doesnt_matter}
. . .
</code></pre>

<p>As you can see, we have multiple PIDs now, simply by adding a line of code and giving our consumers IDs.
But we can take this even further:</p>

<pre><code class="elixir">. . .
    children = [
      worker(GenstageExample.Producer, []),
    ]
    consumers = for id &lt;- 1..(System.schedulers_online * 12) do
                              # helper to get the number of cores on machine
                  worker(GenstageExample.Consumer, [], id: id)
                end

    opts = [strategy: :one_for_one, name: GenstageExample.Supervisor]
    Supervisor.start_link(children ++ consumers, opts)
. . .
</code></pre>

<p>What we are doing here is quite simple.
First, we get the number of core on the machine with <code>System.schedulers_online/0</code>, and from there we simply create a worker just like we had.
Now we have 12 workers per core. This is much more effective.</p>

<pre><code class="elixir">. . .
{#PID&lt;0.229.0&gt;, 63697, :state_doesnt_matter}
{#PID&lt;0.224.0&gt;, 53190, :state_doesnt_matter}
{#PID&lt;0.223.0&gt;, 72687, :state_doesnt_matter}
{#PID&lt;0.238.0&gt;, 69688, :state_doesnt_matter}
{#PID&lt;0.196.0&gt;, 62696, :state_doesnt_matter}
{#PID&lt;0.212.0&gt;, 52713, :state_doesnt_matter}
{#PID&lt;0.233.0&gt;, 72175, :state_doesnt_matter}
{#PID&lt;0.214.0&gt;, 51712, :state_doesnt_matter}
{#PID&lt;0.227.0&gt;, 66190, :state_doesnt_matter}
{#PID&lt;0.234.0&gt;, 58694, :state_doesnt_matter}
{#PID&lt;0.211.0&gt;, 55694, :state_doesnt_matter}
{#PID&lt;0.240.0&gt;, 64698, :state_doesnt_matter}
{#PID&lt;0.193.0&gt;, 50692, :state_doesnt_matter}
{#PID&lt;0.207.0&gt;, 56683, :state_doesnt_matter}
{#PID&lt;0.213.0&gt;, 71684, :state_doesnt_matter}
{#PID&lt;0.235.0&gt;, 53712, :state_doesnt_matter}
{#PID&lt;0.208.0&gt;, 51197, :state_doesnt_matter}
{#PID&lt;0.200.0&gt;, 61689, :state_doesnt_matter}
. . .
</code></pre>

<p>Though we lack any ordering like we would have with a single core, but every increment is being hit and processed.</p>

<p>We can take this a step further and change our broadcasting strategy from the default in our producer:</p>

<pre><code class="elixir">. . .
  def init(counter) do
    {:producer, counter, dispatcher: GenStage.BroadcastDispatcher}
  end
. . .
</code></pre>

<p>What this does is it accumulates demand from all consumers before broadcasting its events to all of them.
If we fire up IEx we can see the implication:</p>

<pre><code class="elixir">. . .
{#PID&lt;0.200.0&gt;, 1689, :state_doesnt_matter}
{#PID&lt;0.230.0&gt;, 1690, :state_doesnt_matter}
{#PID&lt;0.196.0&gt;, 1679, :state_doesnt_matter}
{#PID&lt;0.215.0&gt;, 1683, :state_doesnt_matter}
{#PID&lt;0.237.0&gt;, 1687, :state_doesnt_matter}
{#PID&lt;0.205.0&gt;, 1682, :state_doesnt_matter}
{#PID&lt;0.206.0&gt;, 1695, :state_doesnt_matter}
{#PID&lt;0.216.0&gt;, 1682, :state_doesnt_matter}
{#PID&lt;0.217.0&gt;, 1689, :state_doesnt_matter}
{#PID&lt;0.233.0&gt;, 1681, :state_doesnt_matter}
{#PID&lt;0.223.0&gt;, 1689, :state_doesnt_matter}
{#PID&lt;0.193.0&gt;, 1194, :state_doesnt_matter}
. . .
</code></pre>

<p>Note that some numbers are showing twice now, this is why.</p>

<h2>Setting Up Postgres to Extend Our Producer</h2>

<p>To go further we'll need to bring in a database to store our progress and status.
This is quite simple using <a href="LINKTOLESSON">Ecto</a>.
To get started let's add it and the Postgresql adapter to <code>mix.exs</code>:</p>

<pre><code class="elixir">. . .
  defp deps do
    [
     {:gen_stage, "~&gt; 0.7"},
     {:ecto, "~&gt; 2.0"},
     {:postgrex, "~&gt; 0.12.1"},
    ]
  end
. . .
</code></pre>

<p>Fetch the dependencies and compile:</p>

<pre><code class="shell">$ mix do deps.get, compile
</code></pre>

<p>And now we can add a repo for setup in <code>lib/repo.ex</code>:</p>

<pre><code class="elixir">defmodule GenstageExample.Repo do
  use Ecto.Repo,
    otp_app: :genstage_example
end
</code></pre>

<p>and with this we can set up our config next in <code>config/config.exs</code>:</p>

<pre><code class="elixir">use Mix.Config

config :genstage_example, ecto_repos: [GenstageExample.Repo]

config :genstage_example, GenstageExample.Repo,
  adapter: Ecto.Adapters.Postgres,
  database: "genstage_example",
  username: "your_username",
  password: "your_password",
  hostname: "localhost",
  port: "5432"
</code></pre>

<p>And if we add a supservisor to <code>lib/genstage_example.ex</code> we can now start working with the DB:</p>

<pre><code class="elixir">. . .
  def start(_type, _args) do
    import Supervisor.Spec, warn: false

    children = [
      supervisor(GenstageExample.Repo, []),
      worker(GenstageExample.Producer, []),
    ]
  end
. . .
</code></pre>

<p>But we should also make an interface to do that, so let's import our query interface and repo to the producer:</p>

<pre><code class="elixir">. . .
  import Ecto.Query
  import GenstageExample.Repo
. . .
</code></pre>

<p>Now we need to create our migration:</p>

<pre><code class="shell">$ mix ecto.gen.migration setup_tasks status:text payload:binary
</code></pre>

<p>Now that we have a functional database, we can start storing things.
Let's remove our change in Broadcaster, as we only were doing that to demonstrate that there are others outside the normal default in our Producer.</p>

<pre><code class="elixir">. . .
  def init(counter) do
    {:producer, counter}
  end
. . .
</code></pre>

<h3>Modelling the Rest of the Functionality</h3>

<p>Now that we have all this boilerplate work completed we should come up with a model to run all of this now that we have a simple wired-together producer/consumer model.
At the end of the day we are trying to make a task runner.
To do this, we probably want to abstract the interface for tasks and DB interfacing into their own modules.
To start, let's create our <code>Task</code> module to model our actual tasks to be run:</p>

<pre><code class="elixir">defmodule GenstageExample.Task do
  def enqueue(status, payload) do
    GenstageExample.TaskDBInterface.insert_tasks(status, payload)
  end

  def take(limit) do
    GenstageExample.TaskDBInterface.take_tasks(limit)
  end
end
</code></pre>

<p>This is a <em>really</em> simple interface to abstract a given task's functionality.
We only have 2 functions.
Now, the module they are calling doesn't exist yet, it gives us the ideas we need to build a very simple interface.
These can be broken down as follows:</p>

<ol>
<li><code>enqueue/2</code> - Enqueue a task to be run</li>
<li><code>take/1</code> - Take a given number of tasks to run from the database</li>
</ol>


<p>Now this gives us the interface we need: we can set things to be run, and grab tasks to be run and we can define the rest of the interface.
Let's create an interface with our database in its own module:</p>

<pre><code class="elixir">defmodule GenstageExample.TaskDBInterface do
  import Ecto.Query

  def take_tasks(limit) do
    {:ok, {count, events}} =
      GenstageExample.Repo.transaction fn -&gt;
        ids = GenstageExample.Repo.all waiting(limit)
        GenstageExample.Repo.update_all by_ids(ids), [set: [status: "running"]], [returning: [:id, :payload]]
      end
    {count, events}
  end

  def insert_tasks(status, payload) do
    GenstageExample.Repo.insert_all "tasks", [
      %{status: status, payload: payload}
    ]
  end

  def update_task_status(id, status) do
    GenstageExample.Repo.update_all by_ids([id]), set: [status: status]
  end

  defp by_ids(ids) do
    from t in "tasks", where: t.id in ^ids
  end

  defp waiting(limit) do
    from t in "tasks",
      where: t.status == "waiting",
      limit: ^limit,
      select: t.id,
      lock: "FOR UPDATE SKIP LOCKED"
  end
end
</code></pre>

<p>This one is a bit more complex, but we'll break it down piece by piece.
We have 3 main functions, and 2 private helpers:</p>

<h4>Main Functions</h4>

<ol>
<li><code>take_tasks/1</code></li>
<li><code>insert_tasks/2</code></li>
<li><code>update_task_status/2</code></li>
</ol>


<p>With <code>take_tasks/1</code> we have the bulk of our logic.
This function will be called to grab tasks we have queued to run them.
Let's look at the code:</p>

<pre><code class="elixir">. . .
  def take_tasks(limit) do
    {:ok, {count, events}} =
      GenstageExample.Repo.transaction fn -&gt;
        ids = GenstageExample.Repo.all waiting(limit)
        GenstageExample.Repo.update_all by_ids(ids), [set: [status: "running"]], [returning: [:id, :payload]]
      end
    {count, events}
  end
. . .
</code></pre>

<p>We do a few things here.
First, we go in and we wrap everything in a transaction.
This maintains state in the database so we avoid race conditions and other bad things.
Inside here, we get the ids of all tasks waiting to be executed up to some limit, and set them to <code>running</code> as their status.
We return the <code>count</code> of total tasks and the events to be run in the consumer.</p>

<p>Next we have <code>insert_tasks/2</code>:</p>

<pre><code class="elixir">. . .
  def insert_tasks(status, payload) do
    GenstageExample.Repo.insert_all "tasks", [
      %{status: status, payload: payload}
    ]
  end
. . .
</code></pre>

<p>This one is a bit more simple.
We just insert a task to be run with a given payload binary.</p>

<p>Finally, we have <code>update_task_status/2</code>, which is also quite simple:</p>

<pre><code class="elixir">. . .
  def update_task_status(id, status) do
    GenstageExample.Repo.update_all by_ids([id]), set: [status: status]
  end
. . .
</code></pre>

<p>Here we simple update tasks to the status we want using a given id.</p>

<h4>Helpers</h4>

<p>Our helpers are all called primarily inside of <code>take_tasks/1</code>, but also used elsewhere in the main public API.</p>

<pre><code class="elixir">. . .
  defp by_ids(ids) do
    from t in "tasks", where: t.id in ^ids
  end

  defp waiting(limit) do
    from t in "tasks",
      where: t.status == "waiting",
      limit: ^limit,
      select: t.id,
      lock: "FOR UPDATE SKIP LOCKED"
  end
. . .
</code></pre>

<p>Neither of these has a ton of complexity.
<code>by_ids/1</code> simply grabs all tasks that match in a given list of IDs.</p>

<p><code>waiting/1</code> finds all tasks that have the status waiting up to a given limit.
However, there is one note to make on <code>waiting/1</code>.
We leverage a lock on all tasks being updated so we skip those, a feature available in psql 9.5+.
Outside of this, it is a very simple <code>SELECT</code> statement.</p>

<p>Now that we have our DB interface defined as it is used in the primary API, we can move onto the producer, consumer, and last bits of configuration.</p>

<h3>Producer, Consumer, and Final Configuration</h3>

<h4>Final Config</h4>

<p>We will need to do a bit of configuration in <code>lib/genstage_example.ex</code> to clarify things as well as give us the final functionalities we will need to run jobs.
This is what we will end up with:</p>

<pre><code class="elixir">. . .
  def start(_type, _args) do
    import Supervisor.Spec, warn: false
                          # 12 workers / system core
    consumers = for id &lt;- (0..System.schedulers_online * 12) do
                  worker(GenstageExample.Consumer, [], id: id)
                end
    producers = [
                 worker(Producer, []),
                ]

    supervisors = [
                    supervisor(GenstageExample.Repo, []),
                    supervisor(Task.Supervisor, [[name: GenstageExample.TaskSupervisor]]),
                  ]
    children = supervisors ++ producers ++ consumers

    opts = [strategy: :one_for_one, name: GenstageExample.Supervisor]
    Supervisor.start_link(children, opts)
  end

  def start_later(module, function, args) do
    payload = {module, function, args} |&gt; :erlang.term_to_binary
    Repo.insert_all("tasks", [
                              %{status: "waiting", payload: payload}
                             ])
    notify_producer
  end

  def notify_producer do
    send(Producer, :data_inserted)
  end

  defdelegate enqueue(module, function, args), to: Producer
. . .
</code></pre>

<p>Let's tackle this from the top down.
First, <code>start/2</code>:</p>

<pre><code class="elixir">. . .
  def start(_type, _args) do
    import Supervisor.Spec, warn: false
                          # 12 workers / system core
    consumers = for id &lt;- (0..System.schedulers_online * 12) do
                  worker(GenstageExample.Consumer, [], id: id)
                end
    producers = [
                 worker(Producer, []),
                ]

    supervisors = [
                    supervisor(GenstageExample.Repo, []),
                    supervisor(Task.Supervisor, [[name: GenstageExample.TaskSupervisor]]),
                  ]
    children = supervisors ++ producers ++ consumers

    opts = [strategy: :one_for_one, name: GenstageExample.Supervisor]
    Supervisor.start_link(children, opts)
  end
. . .
</code></pre>

<p>First of all, you will notice we are now defining producers, consumers, and supervisors separately.
I find this convention to work quite well to illustrate the intentions of various processes and trees we are starting here.
In these 3 lists we set up 12 consumers / CPU core, set up a single producer, and then our supervisors for the Repo, as well as one new one.</p>

<p>This new supervisor is run through <code>Task.Supervisor</code>, which is built into Elixir.
We give it a name so it is easily referred to in our GenStage code, <code>GenstageExample.TaskSupervisor</code>.
Now, we define our children as the concatenation of all these lists.</p>

<p>Next, we have <code>start_later/3</code>:</p>

<pre><code class="elixir">. . .
  def start_later(module, function, args) do
    payload = {module, function, args} |&gt; :erlang.term_to_binary
    Repo.insert_all("tasks", [
                              %{status: "waiting", payload: payload}
                             ])
    notify_producer
  end
. . .
</code></pre>

<p>This function takes a module, a function, and an argument.
It then encodes them as a binary using some built-in erlang magic.
From here, we then insert the task as <code>waiting</code>, and we notify a producer that a task has been inserted to run.</p>

<p>Now let's check out <code>notify_producer/0</code>:</p>

<pre><code class="elixir">. . .
  def notify_producer do
    send(Producer, :data_inserted)
  end
. . .
</code></pre>

<p>This method is quite simple.
We send our producer a message, <code>:data_inserted</code>, simply so that it knows what we did.
The message here is arbitrary, but I chose this atom to make the meaning clear.</p>

<p>Last, but not least we do some simple delegation:</p>

<pre><code class="elixir">. . .
  defdelegate enqueue(module, functions, args), to : Producer
. . .
</code></pre>

<p>This simply makes it so if we call <code>GenstageExample.enqueue(module, function, args)</code> that it will be delegated to the same method in our producer.</p>

<h3>Producer Setup</h3>

<p>Our producer doesn't need a ton of work.
first, we'll alter our <code>handle_demand/2</code> to actually do something with our events:</p>

<pre><code class="elixir">. . .
  def handle_demand(demand, state) when demand &gt; 0 do
    serve_jobs(demand + state)
  end
. . .
</code></pre>

<p>We haven't defined <code>serve_jobs/2</code> yet, but we'll get there.
The concept is simple, when we get a demand and demand is > 0, we do some work to the tune of demand + the current state's number of jobs.</p>

<p>Now that we will be sending a message to the producer when we run <code>start_later/3</code>, we will want to respond to it with a <code>handle_info/2</code> call:</p>

<pre><code class="elixir">. . .
  def handle_info(:enqueued, state) do
    {count, events} = GenstageExample.Task.take(state)
    {:noreply, events, state - count}
  end
. . .
</code></pre>

<p>With this, we simply respond by taking the number of tasks we are told to get ready to run.</p>

<p>Now let's define <code>serve_jobs/1</code>:</p>

<pre><code class="elixir">. . .
  def serve_jobs limit do
    {count, events} = GenstageExample.Task.take(limit)
    Process.send_after(@name, :enqueued, 60_000)
    {:noreply, events, limit - count}
  end
. . .
</code></pre>

<p>Now, we are sending a process in one minute that to our producer telling it that it should respond to <code>:enqueued</code>.
Note that we call the process module with <code>@name</code>, which we will need to add at the top as a module attribute:</p>

<pre><code class="elixir">. . .
  @name __MODULE__
. . .
</code></pre>

<p>Let's define that last function to handle the <code>:enqueued</code> message now, too:</p>

<pre><code class="elixir">. . .
  def handle_cast(:enqueued, state) do
    serve_jobs(state)
  end
. . .
</code></pre>

<p>This will simply serve jobs when we tell the producer they have <code>state</code> number of enqueued and to respond.</p>

<h2>Setting Up the Consumer for Real Work</h2>

<p>Our consumer is where we do the work.
Now that we have our producer storing tasks, we want to have the consumer handle this as well.
There is a good bit of work to be done here tying into our work so far.
The core of the consumer is <code>handle_events/3</code>, lets flesh out the functionality we wish to have there and define it as we go further:</p>

<pre><code class="elixir">. . .
  def handle_events(events, _from, state) do
    for event &lt;- events do
      %{id: id, payload: payload} = event
      {module, function, args} = payload |&gt; deconstruct_payload
      task = start_task(module, function, args)
      yield_to_and_update_task(task, id)
    end
    {:noreply, [], state}
  end
. . .
</code></pre>

<p>At its core, this setup simple just wants to run a task we decode the binary of.
To do this we get the data from the event, deconstruct it, and then start and yield to a task.
These functions aren't defined yet, so let's create them:</p>

<pre><code class="elixir">. . .
  def deconstruct_payload payload do
    payload |&gt; :erlang.binary_to_term
  end
. . .
</code></pre>

<p>We can use Erlang's built-in inverse of our other <code>term_to_binary/1</code> function to get our module, function, and args back out.
Now we need to start the task:</p>

<pre><code class="elixir">. . .
  def start_task(mod, func, args) do
    Task.Supervisor.async_nolink(TaskSupervisor, mod, func, args)
  end
. . .
</code></pre>

<p>Here we leverage the supervisor we created at the beginning to run this in a task.
Now we need to define <code>yield_to_and_update_task/2</code>:</p>

<pre><code class="elixir">. . .
  def yield_to_and_update_task(task, id) do
    task
    |&gt; Task.yield(1000)
    |&gt; yield_to_status(task)
    |&gt; update(id)
  end
. . .
</code></pre>

<p>Now this brings in more pieces we've yet to define, but the core is simple.
We wait 1 second for the task to run.
From here, we respond to the status it returns (which will either be <code>:ok</code>, <code>:exit</code>, or <code>nil</code>) and handle it as such.
After that we update our task via our DB interface to get things current.
Let's define <code>yield_to_status/2</code> for each of the scenarios we mentioned:</p>

<pre><code class="elixir">. . .
  def yield_to_status({:ok, _}, _) do
    "success"
  end

  def yield_to_status({:exit, _}, _) do
    "error"
  end

  def yield_to_status(nil, task) do
    Task.shutdown(task)
    "timeout"
  end
. . .
</code></pre>

<p>These simple handle the atom being returned from the process and respond appropriately.
If it takes more than a second, we need to shut it down because otherwise it would just hang forever.</p>

<p>If we make another method to update the database after consumption, we are set to go:</p>

<pre><code class="elixir">. . .
  defp update(status, id) do
    GenstageExample.TaskDBInterface.update_task_status(id, status)
  end
. . .
</code></pre>

<p>And here we just call it through our database interface and update the status after yielding to allow the task time to run.</p>

<p>From this, we can see our finalized consumer:</p>

<pre><code class="elixir">defmodule GenstageExample.Consumer do
  alias Experimental.GenStage
  use GenStage
  alias GenstageExample.{Producer, TaskSupervisor}

  def start_link do
    GenStage.start_link(__MODULE__, :state_doesnt_matter)
  end

  def init(state) do
    {:consumer, state, subscribe_to: [Producer]}
  end

  def handle_events(events, _from, state) do
    for event &lt;- events do
      %{id: id, payload: payload} = event
      {module, function, args} = payload |&gt; deconstruct_payload
      task = start_task(module, function, args)
      yield_to_and_update_task(task, id)
    end
    {:noreply, [], state}
  end

  defp yield_to_and_update_task(task, id) do
    task
    |&gt; Task.yield(1000)
    |&gt; yield_to_status(task)
    |&gt; update(id)
  end

  defp start_task(mod, func, args) do
    Task.Supervisor.async_nolink(TaskSupervisor, mod  , func, args)
  end

  defp yield_to_status({:ok, _}, _) do
    "success"
  end

  defp yield_to_status({:exit, _}, _) do
    "error"
  end

  defp yield_to_status(nil, task) do
    Task.shutdown(task)
    "timeout"
  end

  defp update(status, id) do
    GenstageExample.TaskDBInterface.update_task_status(id, status)
  end

  defp deconstruct_payload payload do
    payload |&gt; :erlang.binary_to_term
  end
end
</code></pre>

<p>Now, if we go into IEx:</p>

<pre><code class="elixir">$ iex -S mix
iex&gt; GenstageExample.enqueue(IO, :puts, ["wuddup"])
#=&gt; 
16:39:31.014 [debug] QUERY OK db=137.4ms
INSERT INTO "tasks" ("payload","status") VALUES ($1,$2) [&lt;&lt;131, 104, 3, 100, 0, 9, 69, 108, 105, 120, 105, 114, 46, 73, 79, 100, 0, 4, 112, 117, 116, 115, 108, 0, 0, 0, 1, 109, 0, 0, 0, 6, 119, 117, 100, 100, 117, 112, 106&gt;&gt;, "waiting"]
:ok

16:39:31.015 [debug] QUERY OK db=0.4ms queue=0.1ms
begin []

16:39:31.025 [debug] QUERY OK source="tasks" db=9.6ms
SELECT t0."id" FROM "tasks" AS t0 WHERE (t0."status" = 'waiting') LIMIT $1 FOR UPDATE SKIP LOCKED [49000]

16:39:31.026 [debug] QUERY OK source="tasks" db=0.8ms
UPDATE "tasks" AS t0 SET "status" = $1 WHERE (t0."id" = ANY($2)) RETURNING t0."id", t0."payload" ["running", [5]]

16:39:31.040 [debug] QUERY OK db=13.5ms
commit []
iex(2)&gt; wuddup

16:39:31.060 [debug] QUERY OK source="tasks" db=1.3ms
UPDATE "tasks" AS t0 SET "status" = $1 WHERE (t0."id" = ANY($2)) ["success", [5]]
</code></pre>

<p>It works and we are storing and running tasks!</p>
</br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br><h1>Exploring Git: From git init to a KV store</h1>

<h4>This is a talk I gave at <a href="http://columbusrb.com">ColumbusRB</a>, the slides can be found <a href="http://slides.com/bobbygrayson/deck-1/live#/">here</a></h4>

<h2>This eventually evolved into <a href="https://www.github.com/ybur-yug/gkv">this gem</a></h2>

<h2>Why?</h2>

<p>It was a good excuse to get to know git's innards a bit better, as well as work on something
that, while somewhat useless, is technically functional and interesting.</p>

<h2>For Who?</h2>

<p>Anyone with a casual knowledge of git shouldn't get too lost and hopefully learns something.
Ambitious beginners are more than welcome, and <a href="https://www.twitter.com/yburyug">tweet me</a> if something comes up
that you think could make it better :)</p>

<h2>Beginning</h2>

<pre><code class="bash">mkdir git_exploration
cd git_exploration
git init
</code></pre>

<p>This gets us a git repo created. Let's check out what we have:</p>

<pre><code>ls -a
. .. .git
</code></pre>

<p>And if we check out the <code>.git</code> subdirectory in our editor:</p>

<pre><code>$ tree .git

.git
├── branches
├── config
├── description
├── HEAD
├── hooks
│   ├── applypatch-msg.sample
│   ├── commit-msg.sample
│   ├── post-update.sample
│   ├── pre-applypatch.sample
│   ├── pre-commit.sample
│   ├── prepare-commit-msg.sample
│   ├── pre-push.sample
│   ├── pre-rebase.sample
│   └── update.sample
├── info
│   └── exclude
├── objects
│   ├── info
│   └── pack
└── refs
    ├── heads
        └── tags

9 directories, 13 files
</code></pre>

<p>A note, you may need to install tree depending on your OS. On Ubuntu, I used</p>

<p><code>sudo apt-get install tree</code></p>

<p>I imagine it is about the same on mac with <code>brew</code>. I Have no idea on Windows as I barely know how to list
a directory in Powershell (sorry).</p>

<p>Okay, so this doesn't look too crazy. Let's open up some of the stuff we have on initialization in
here.</p>

<p><code>.git/info/exclude</code>
```</p>

<h1>git ls-files --others --exclude-from=.git/info/exclude</h1>

<h1>Lines that start with '#' are comments.</h1>

<h1>For a project mostly in C, the following would be a good set of</h1>

<h1>exclude patterns (uncomment them if you want to use them):</h1>

<h1>*.[oa]</h1>

<h1>*~</h1>

<pre><code>
Okay, so it appears that this opens up with the command that the system would use to govern this
behaviour. Knowing a bit about git, one can reasonably infer that this is going to work in hijinks
with the `.gitignore` file that one can use to ignore certain files.

`.git/config`
</code></pre>

<p>[core]
repositoryformatversion = 0
filemode = true
bare = false
logallrefupdates = true
```
It would appear this is just some general configuration for a boilerplate initialized repo.</p>

<p><code>.git/description</code>
<code>
Unnamed repository; edit this file 'description' to name the repository.
</code>
Here it seems we can name our little project</p>

<p><code>.git/refs/HEAD</code>
<code>
ref: refs/heads/master
</code>
This seems to be referencing the current <code>HEAD</code>.</p>

<h4>HEAD</h4>

<p>HEAD is a reference to the last commit in the current checked out branch.</p>

<h2>Adding A File</h2>

<pre><code class="bash">echo "# Git Exploration" &gt; README.md
git add README.md
git commit -m 'initial commit'
</code></pre>

<p>Once we do this, we can check out a new directory structure:</p>

<pre><code>$ tree .git
.git
├── branches
├── COMMIT_EDITMSG
├── config
├── description
├── HEAD
├── hooks
│   ├── applypatch-msg.sample
│   ├── commit-msg.sample
│   ├── post-update.sample
│   ├── pre-applypatch.sample
│   ├── pre-commit.sample
│   ├── prepare-commit-msg.sample
│   ├── pre-push.sample
│   ├── pre-rebase.sample
│   └── update.sample
├── index
├── info
│   └── exclude
├── logs
│   ├── HEAD
│   └── refs
│       └── heads
│           └── master
├── objects
│   ├── 1b
│   │   └── f567a9cee63cd3036628c1519b818461905b27
│   ├── 9d
│   │   └── aeafb9864cf43055ae93beb0afd6c7d144bfa4
│   ├── c1
│   │   └── 2d7c0ed49ad9c7aa938743ba6fdee54b6b7fe1
│   ├── info
│   └── pack
└── refs
  ├── heads
      │   └── master
          └── tags

15 directories, 21 files
</code></pre>

<p>It appears we have some simple additions with adding one file. To start, we have expanded our
info directory to now include a <code>logs</code> directory. We also have several subdirectories inside of our
<code>objects</code> directory now, each containing a hash. refs subdirectory <code>heads</code> now includes a
<code>master</code> file, and we also have added <code>COMMIT_EDITMSG</code>, and index at the root level of <code>.git</code>.</p>

<p>The three hashes in our <code>objects</code> directory represent 3 data structures git utilizes. These are
a <code>blob</code>, a <code>tree</code>, and a <code>commit</code>. We will go into these more in-depth later.</p>

<p>If we examine <code>COMMIT_EDITMSG</code> we see:</p>

<pre><code>initial commit
</code></pre>

<p>Logging our commit message.</p>

<h2>Making A Branch</h2>

<p>Let's create a new branch to further expand this interesting <code>.git</code> directory.</p>

<pre><code class="bash">git checkout -b my_feature_branch
</code></pre>

<p>What this does is use the <code>git checkout</code> command and the <code>-b</code> flag to create and checkout a new branch
named whatever follows <code>-b</code>. We have created a branch called <code>my_feature_branch</code>. The reason I have
called it a feature branch specifically is because this is a common flow for managing an application's
development with multiple authors. Let's see what changed:</p>

<pre><code class="bash">$ tree .git
.git
├── branches
├── COMMIT_EDITMSG
├── config
├── description
├── HEAD
├── hooks
│   ├── applypatch-msg.sample
│   ├── commit-msg.sample
│   ├── post-update.sample
│   ├── pre-applypatch.sample
│   ├── pre-commit.sample
│   ├── prepare-commit-msg.sample
│   ├── pre-push.sample
│   ├── pre-rebase.sample
│   └── update.sample
├── index
├── info
│   └── exclude
├── logs
│   ├── HEAD
│   └── refs
│       └── heads
│           ├── master
│           └── my_feature_branch
├── objects
│   ├── 1b
│   │   └── f567a9cee63cd3036628c1519b818461905b27
│   ├── 9d
│   │   └── aeafb9864cf43055ae93beb0afd6c7d144bfa4
│   ├── c1
│   │   └── 2d7c0ed49ad9c7aa938743ba6fdee54b6b7fe1
│   ├── info
│   └── pack
└── refs
    ├── heads
        │   ├── master
            │   └── my_feature_branch
                └── tags

15 directories, 23 files
</code></pre>

<p>Now, if you look at <code>.git/branches/refs/heads/</code> we can see we have added <code>my_feature_branch</code>. If we
look at our <code>HEAD</code> files, we will see an addition to it as well.</p>

<p><code>.git/logs/refs/HEAD</code>
<code>
... 1433706112 -0400    commit (initial): initial commit
... 1433796852 -0400    checkout: moving from master to my_feature_branch
</code></p>

<p><code>.git/refs/HEAD</code>
<code>bash
ref: refs/heads/my_feature_branch
</code></p>

<p>It has logged our checkout and pointed us at the new branch. Also it is worth noting we have not created
any new objects. This is one of the finer pieces of git, it is differentials rather than copies and
copies as one would have saving <code>my_documentv1</code>, <code>my_documentv2</code>, <code>my_documentvN</code> etc.</p>

<p>Let's add another commit by creating a directory in here and logging its boilerplate.</p>

<pre><code>mkdir test &amp;&amp; echo "test" &gt; test/file.txt
cd test
git status
# =&gt; ./
</code></pre>

<p>Okay, lets add this project and commit. If you don't have Volt installed locally, feel free to substitute it
with anything from rails to django to meteor. It doesn't really matter for our studies here.</p>

<pre><code class="bash">cd ..
git add test
git commit -m 'add file + dir'
</code></pre>

<p>Now, let us further check out our changes in the git file tree:</p>

<pre><code>.git
├── branches
├── COMMIT_EDITMSG
├── config
├── description
├── HEAD
├── hooks
│   ├── applypatch-msg.sample
│   ├── commit-msg.sample
│   ├── post-update.sample
│   ├── pre-applypatch.sample
│   ├── pre-commit.sample
│   ├── prepare-commit-msg.sample
│   ├── pre-push.sample
│   ├── pre-rebase.sample
│   └── update.sample
├── index
├── info
│   └── exclude
├── logs
│   ├── HEAD
│   └── refs
│       └── heads
│           ├── master
│           └── my_feature_branch
├── objects
│   ├── 1b
│   │   └── f567a9cee63cd3036628c1519b818461905b27
│   ├── 2b
│   │   └── 297e643c551e76cfa1f93810c50811382f9117
│   ├── 5e
│   │   └── c1f4ac6015a50b5d8462582d7ae50d7029d012
│   ├── 70
│   │   └── cc10cfcc770f6b0ea11cdd9a876ee1a3184d77
│   ├── 9d
│   │   └── aeafb9864cf43055ae93beb0afd6c7d144bfa4
│   ├── c1
│   │   └── 2d7c0ed49ad9c7aa938743ba6fdee54b6b7fe1
│   ├── info
│   └── pack
└── refs
    ├── heads
        │   ├── master
            │   └── my_feature_branch
                └── tags

18 directories, 26 files
</code></pre>

<p>Now, if we look at <code>COMMIT_EDITMSG</code></p>

<pre><code>add file + dir
</code></pre>

<p>And again it is our latest message. The other major change is we have a ton of new objects.
Just to see what happens, let's checkout master and see if anything changes:</p>

<pre><code class="bash">git checkout master
</code></pre>

<p>and we get the same tree, but we can check out our HEAD item in the <code>.git</code> directory.</p>

<p>So we have the same thing, but our <code>HEAD</code> file reads:</p>

<pre><code>ref: refs/heads/master
</code></pre>

<p>So we can now see this is our constant anchor as we navigate changes.</p>

<h2>Objects</h2>

<pre><code class="bash">$ find .git/objects
.git/objects/pack
.git/objects/info
.git/objects/b7
.git/objects/b7/37ff03e6f22c28bc4786f4b11925f2d864e00
...
.git/objects/4c
.git/objects/4c/2be36223ca4d07cbd7ce8c28419ba1c4144334
</code></pre>

<p>Here we see a list of a butt ton of what looks like SHA-1 hashes. So what is git doing with all of
these?</p>

<p>Let's create a clean repository and proceed to start an empty git repo in it.</p>

<p><code>cd .. &amp;&amp; mkdir git_testing</code></p>

<p>Initialize a repository</p>

<p><code>git init</code></p>

<p>And now, let's try creating one of these hash objects. We do this with the git command <code>hash-object</code>.
If we simply use some bash, we can do this without even needing a file. By doing this we will pipe
an echoed statement into the hash-object command through stdin and receive our hash in stdout.</p>

<p><code>echo 'test content' | git hash-object -w --stdin</code></p>

<pre><code class="bash">d670460b4b4aece5915caf5c68d12f560a9fe3e4
</code></pre>

<p>So, it took the string 'test content' and hashed it then spat it back out in SHA-1 form. Cool.</p>

<p>We should examine this further.</p>

<p><code>echo "test" &gt; test.txt</code></p>

<p><code>git hash-object -w test.txt</code></p>

<p><code>vim test.txt</code>
<code>txt
test
test 2
</code></p>

<p>If we save this change and run the command again:</p>

<p><code>git hash-object -w test.txt</code></p>

<p><code>6375a2690c50e28c8c351fc552e2fd8a24b01031</code></p>

<p>And if we check out our objects directory we can now see what git has done:</p>

<pre><code class="bash">bobby@bobdawg-devbox:~/code/git_test/test$ find .git/objects/ -type f
.git/objects/9d/aeafb9864cf43055ae93beb0afd6c7d144bfa4
.git/objects/63/75a2690c50e28c8c351fc552e2fd8a24b01031
</code></pre>

<p>It has a hash for each of our objects saved. Woo! But wait. We haven't committed anything. How is git
tracking all this?</p>

<p>Well it turns out git just keeps some headers with these SHA-1's, and does a bunch of cool stuff so it
only has to track changes. Not entire new versions of each document. So each of these objects simply
represents a given state of some blob of our data.'</p>

<p>If we dive in to do the reverse of this, we can look up our input using git's <code>cat-file</code> command, which
intakes a hash.</p>

<p><code>git cat-file 6375a2690c50e28c8c351fc552e2fd8a24b01031</code></p>

<pre><code>test
test 2
</code></pre>

<p>Now, if we make another change on this, we will be able to see the new version.</p>

<p><code>vim test.txt</code>
<code>
test "one"
</code></p>

<p>If we delete everything and replace it with this line, the do our typical:</p>

<p><code>git hash-object -w test.txt</code></p>

<p>We get a new hash, which when called with <code>cat-file</code> will output a the new value,
while still keeping our old object in history.</p>

<p>What this really is at it's core is a key:value store. Using this, we can leverage
a very simple database that only relies on single key/value types (symbol, string)
to store any data we need to and look it up. So, let's move on.</p>

<h2>Aside - Git: A Directed Acyclic Graph</h2>

<p>In the broadest of terms, git is a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">directed acyclic graph</a>. This sounds quite fancy and/or
scary depending on how hard in the paint you go with mathematica, but it truly isn't that crazy.
Let's ignore Wikipedia's terse entry, and instead break it down on our own.</p>

<h2>Storage</h2>

<p>In its most basic state, git functions to make one of these graphs connecting a series of objects. These
objects also have a handful of types.</p>

<h3>Types</h3>

<h4>Blob</h4>

<p>A <code>blob</code> is a blob of bytes. It usually is a file, but can also be a symlink or a myriad of other things.
It is all simply semantics as long as there is a pointer to the <code>blob</code>.</p>

<h4>Tree</h4>

<p>Directories are represented by a <code>tree</code> object. They refer to <code>blobs</code> and other <code>trees</code>. When one of these nodes
(a <code>tree</code> or a <code>blob</code>, in this case) points to another in the graph, it <em>depends</em> on that node. It is a connection
that cannot be broken. You can garbage collect, filesystem check, and a myriad of other functions
but we do not need to truly know more other than that without a referent of dependence, a node
is essentially useless, as it is disconnected.</p>

<h4>Commit</h4>

<p>A <code>commit</code> refers to a tree that represents the state of a group of <code>blobs</code>' state at the time of that given
commit. It refers to a range <code>X</code> of other commits that are its parents. More than one parent means a merge,
no parent means an initial commit, and a single just means its a regular old commit. As we saw earlier,
the body of a commit is its message.</p>

<h4>Refs</h4>

<p>Refs have two functions: storing <code>HEAD</code>s, and <code>branches</code>. They are essentially notes left on a given
node. These notes can be moved around freely and arent stored in history, and arent transferred
between repositories. They are simply a means to namespace 'I am working here'.</p>

<h4>Visualizing It</h4>

<p><img src="http://eagain.net/articles/git-for-computer-scientists/git-history.6.dot.svg" alt="A Typical remote/local DAG" /></p>

<p>As you can see, these nodes form a <code>tree</code> of functioning between master and a remote with a few merges
thrown in (any of the nodes with 2 parents).</p>

<h2>Git as a Key:Value Store</h2>

<h3>Note: Do not use this for real software</h3>

<h3>Addendum: Apparently <a href="http://crates.io">crates.io</a> does this, and those guys are wicked smart, so maybe its a good idea but definitely not at this capacity we are building</h3>

<p>Since the <code>cat-file</code> and <code>hash_object</code> pattern functions simply as a key:value store for git, we
can utilize this to our advantage. Normal storing large strings in-memory in Ruby can get quite
taxing, but if we simply store the string of the SHA-1 hash to a given key, we can greatly reduce
the memory footprint of our master dictionary and allow it to grow far larger in size (theoretically).
So, let's code up a pseudo-class for this and fill it in after we get that far.</p>

<p><code>vim git_database.rb</code>
```ruby
module GitDatabase
class Database
  def initialize
    # set initliazers and master dictionary
  end</p>

<p>  def set
    # set a given key to a value
  end</p>

<p>  def get
    # get a given key's value
  end</p>

<p>  def hash_object
    # hash a given input that is coerced to a string
  end</p>

<p>  def cat_file
    # cat out a given file based on SHA-1 hash
  end
end
end
```</p>

<p>We can now tackle this piece by piece.</p>

<h4>Initializers</h4>

<p><code>vim git_database.rb</code>
```ruby
...
class Database
  attr_accessor :items</p>

<p>  def initialize
    @items = {}
    <code>git init</code>
  end
...</p>

<pre><code>
Simple enough. We ensure we have a git repository initialized, and we ensure that we setup our
master dictionary.

#### Hashing
`vim git_database.rb`
</code></pre>

<p>...
  def hash_object(string)
    # What do we do?
  end
...
```</p>

<p>Well, to start, lets fire up irb and see what we can do calling git from Ruby.</p>

<pre><code>irb
irb(main):001:0&gt; string = "test"
=&gt; "test"
irb(main):002:0&gt; `echo #{string}`
=&gt; "test\n"
irb(main):003:0&gt; `echo #{string} | git hash-object -w --stdin`
=&gt; "9daeafb9864cf43055ae93beb0afd6c7d144bfa4\n"
irb(main):004:0&gt; `echo #{string} | git hash-object -w --stdin`.strip!
=&gt; "9daeafb9864cf43055ae93beb0afd6c7d144bfa4"
</code></pre>

<p>So, it appears we can essentially call exactly what we were prior. We can now reasonable change the
function to be:</p>

<pre><code class="ruby">...
  def hash_object(data)
    `echo #{data} | git hash-object -w --stdin`.strip!
  end
...
</code></pre>

<p>And this will get that blob hashed up and stored for us. Now, notice we get the exact hash here, but if
we do a</p>

<p><code>find .git/objects -type f</code></p>

<p>and look at a sampling of what we get:</p>

<pre><code>.git/objects/e4/ea753518a47496350473b8eb0972ad2985d964
</code></pre>

<p>You might notice that objects has subdirectories of seemingly random 2 letter combos. There are the first 2
characters of the hash, but git does this to save on overhead. So, if looking in the git directory for hashes
you must account for the parent directory of the longer string to get the entire SHA-1.</p>

<h4>Cattin'</h4>

<p>Since the prior method returns us a hash directly, we can use the same command as earlier and interpolate.</p>

<pre><code class="ruby">...
  def cat_file(hash)
    `git cat-file -p #{hash}`
  end
...
</code></pre>

<p>And now we just need a way to map keys to the hashes we have saved.</p>

<h4>Set</h4>

<pre><code class="ruby">...
  def set
    # get key, data
    # hash data
    # save key to SHA-1 hash in @items
  end
...
</code></pre>

<p>This is a reasonable fleshed out idea of a simple set implementation. So, first we need to take in a key:</p>

<pre><code class="ruby">...
  def set(key, value)
    hash = hash_object(value.to_s)
    @items[key] = value
  end
...
</code></pre>

<p>And now, we can move onto a get implementation</p>

<h4>Get</h4>

<p>To get, we have a little more to do. We will have a key, and that gets us an SHA-1 hash. However,
we still need to decrypt it using our <code>cat_file</code> function. So, if we pseudocode this out:</p>

<pre><code class="ruby">...
  def get
    # find hash by key
    # cat-file hash
  end
...
</code></pre>

<p>So, with our functions already set up we can simply go in and do this:</p>

<pre><code class="ruby">...
  def get(key)
    cat_file(@items[key.to_s])
  end
...
</code></pre>

<p>And now, we have a finished class that can function as a reasonable minimal database. Consider
it an equally ghetto but more interesting version of the good 'ole CSV store.</p>

<h3>Accessing Object History</h3>

<p>Currently we are only returning the latest version of a given item. However, we have already stored it at every
state it hash ever been hashed. So, if we were to add in some functionality for grabbing versions, it would be
quite simple.</p>

<pre><code class="ruby">module GitDatabase
  class Database
    attr_accessor :items
    def initialize
      `git init`
      @items = {}
    end

    def set(key, value)
      unless key in @items.keys
        @items[key] = [hash_object(value)]
      else
        @items[key] &lt;&lt; value
      end
    end

    def get(key)
      cat_file(@items[key.to_s].first)
    end

    def get_version(key, version)
      # 0 = latest, numbers = older
      @items[key][version]
    end

    def versions(key)
      @items[key].count
    end

    private

    def hash_object(data)
      `echo #{data.to_s} | git hash-object -w --stdin`.strip!
    end

    def cat_file(hash)
      `git cat-file -p #{hash}`
    end
  end
end
</code></pre>

<p>Now, we can do something like:</p>

<pre><code class="ruby">db = GitDatabase::Database.new
db.set("Apples", "12")
db.get("Apples")
# =&gt; "12"
db.set("Apples", "10")
db.get_version("Apples", 0)
# =&gt; "12"
db.get("Apples")
# =&gt; "10"
</code></pre>

<p>Abd to use this. We can make a very simple sinatra API to take input remotely:</p>

<pre><code class="ruby">... # below the class
require 'sinatra'
require 'json'
DB = GitDatabase::Database.new
post '/set' do
DB.set(params['key'], params['value']
rescue
  { error: 'please send key and value parameters' }.to_json
end
end

get '/get/:key' do
{ result: DB.get(params['key'] }.to_json
end
</code></pre>

<p>This is a very simple wrapper, but if gives the general idea of where you could take this with a toy application.</p>

<h2>Happy Hacking, and check out <a href="http://github.com/ybur-yug/gkv">Gkv</a> to actually use this in a small app</h2>
</html>

